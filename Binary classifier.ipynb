{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazua classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For solving this exercise, we would use popular scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Logistic Regresion classifier we have 27.428571428571423 % false negative ratio\n",
      "For Nearest Neighbors classifier we have 17.14285714285714 % false negative ratio\n",
      "For Linear SVM classifier we have 28.000000000000004 % false negative ratio\n",
      "For RBF SVM classifier we have 0.5714285714285672 % false negative ratio\n",
      "For Gaussian Process classifier we have 28.57142857142857 % false negative ratio\n",
      "For Decision Tree classifier we have 17.714285714285715 % false negative ratio\n",
      "For Random Forest classifier we have 16.000000000000004 % false negative ratio\n",
      "For Neural Net classifier we have 42.85714285714286 % false negative ratio\n",
      "For AdaBoost classifier we have 16.000000000000004 % false negative ratio\n",
      "For Naive Bayes classifier we have 36.57142857142858 % false negative ratio\n",
      "For QDA classifier we have 36.0 % false negative ratio\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "data = pd.read_excel('./HR-motor-samples.xlsx')\n",
    "\n",
    "#Rename columns and preprocessing\n",
    "data.columns = ['index','input1','input2','result']\n",
    "data.drop(columns=['index'],inplace=True)\n",
    "data['result'] = data['result'].apply(lambda value: value == 'pass')\n",
    "\n",
    "#Divide in input and output\n",
    "X = np.array(data[['input1','input2']])\n",
    "Y = np.array(data['result'])\n",
    "\n",
    "\n",
    "names = [\"Logistic Regresion\",\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "#First, let's find a classifier that better fits out data \n",
    "classifiers = [\n",
    "    LogisticRegression(solver='lbfgs'),\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    model = clf.fit(X, Y)\n",
    "    accuracy = (clf.score(X,Y))\n",
    "    \n",
    "\n",
    "    print(\"For {} classifier we have {} % false negative ratio\".format(name,(1-accuracy) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter input 1\n",
      "90\n",
      "Enter input 2\n",
      "95\n",
      "For input [['90' '95']] we have that result will be [ True]\n"
     ]
    }
   ],
   "source": [
    "#As seen before, the best performance was given by Radial Basis Function kernel Support Vector Machine\n",
    "rbfSVM = SVC(gamma=2, C=1)\n",
    "rbfSVM.fit(X,Y)\n",
    "\n",
    "print(\"Enter input 1\")\n",
    "a = input() \n",
    "print(\"Enter input 2\")\n",
    "b = input()\n",
    "pred = np.array([[a,b]])\n",
    "print(\"For input {} we have that result will be {}\".format(pred,rbfSVM.predict(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
